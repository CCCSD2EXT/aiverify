export const cid = "fairness_metrics_toolbox_for_classification"

{props.getResults(cid)?(
  <>
    <div>
    <h3>Fairness for Classification</h3>
    The fairness test shows how correctly your model has predicted the selected sensitive feature(s) (Selected: {props.getResults(cid).sensitive_feature.join(", ")}). These fairness metrics are calculated based on the performance measurement for classification models. The table shows a list of fairness metrics that are generated in this report.
    <br/>
    <table style={{width:"100%", padding:"5px", textAlign:"left", borderCollapse:'collapse'}} border="1">
      <tbody>
        <tr style={{padding:"5px"}}>
          <th>Fairness Metrics</th>
          <th>Description</th>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>False Negative Rate Parity</td>
          <td>The difference between two groups based on the percentage of incorrect predictions among the actual negative values.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>False Positive Rate Parity</td>
          <td>The difference between two groups based on the percentage of incorrect predictions among the actual positive values.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>False Discovery Rate Parity</td>
          <td>The difference between two groups based on the percentage of incorrect predictions among those that are predicted as positive.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>False Omission Rate Parity</td>
          <td>The diffrence between two groups based on the percentage of incorrect predictions among those that are predicted as negative.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>True Positive Rate Parity</td>
          <td>The difference between two groups based on the percentage of correct predictions among the actual positive values.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>True Negative Rate Parity</td>
          <td>The difference between two groups based on the percentage of correct predictions among the actual negative values.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>Positive Predictive Value Parity</td>
          <td>The difference between two groups based on the percentage of correct predictions among the labels that are predicted as positive.</td>
        </tr>
        <tr style={{padding:"5px"}}>
          <td>Negative Predictive Value Parity</td>
          <td>The difference between two groups based on the percentage of correct predictions among the labels that are predicted as negative.</td>
        </tr>
      </tbody>
    </table>
  </div>
  </>
): (
  <div style={{ 
    width: props.width, 
    height: props.height, 
    display: 'flex', 
    justifyContent: 'center', 
    alignItems: 'center',
    flexDirection: 'column',
    background: '#f8f9fa',
    border: '1px dashed #dee2e6',
    borderRadius: '4px',
    padding: '20px',
    textAlign: 'center' 
  }}>
    <div style={{ fontSize: '18px', fontWeight: 'bold', color: '#dc3545', marginBottom: '10px' }}>
      Report is incomplete
    </div>
    <div style={{ color: '#6c757d' }}>
      No Test Result is selected for Fairness Metrics Toolbox for Classification algorithm. 
      Please select appropriate test results in the Data Selection page.
    </div>
  </div>
)}